{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# governance & API\n",
    "\n",
    "## mlFlow\n",
    "\n",
    "Making experiments repeatable, bringing structure to it and tracking the best parameters.\n",
    "https://mlflow.org\n",
    "\n",
    "\n",
    "In case you run this locally execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "otherwise, directly go to: http://localhost:5000 to view the UI.\n",
    "\n",
    "\n",
    "Lets log some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow experiments create --experiment-name first_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow experiments list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mlflow import log_metric, log_param, log_artifact\n",
    "\n",
    "# Log a parameter (key-value pair)\n",
    "log_param(\"param1\", 5)\n",
    "\n",
    "# Log a metric; metrics can be updated throughout the run\n",
    "log_metric(\"foo\", 1)\n",
    "log_metric(\"foo\", 2)\n",
    "log_metric(\"foo\", 3)\n",
    "\n",
    "# Log an artifact (output file)\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    f.write(\"Hello world!\")\n",
    "log_artifact(\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And come back to the UI to take a look at the result.\n",
    "\n",
    "Please be aware of: https://github.com/mlflow/mlflow/issues/884 somehow it does not fully work in the docker container. But the artifact is nicely logged when running locally.\n",
    "\n",
    "\n",
    "## mlFlow projects\n",
    "\n",
    "Structuring the code https://github.com/mlflow/mlflow-example allows for easy experimentation\n",
    "\n",
    "- dependencies\n",
    "- parameters\n",
    "\n",
    "\n",
    "Launch:\n",
    "\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "in a new terminal (in the same folder.\n",
    "\n",
    "Then, create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow experiments create --experiment-name second_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow run --experiment-name second_run https://github.com/mlflow/mlflow-example.git -P alpha=5\n",
    "!mlflow run --experiment-name second_run https://github.com/mlflow/mlflow-example.git -P alpha=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go again back to http://localhost:5000/#/\n",
    "\n",
    "- look at the results\n",
    "- compare them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API\n",
    "\n",
    "- models only bring value when others can use them\n",
    "- mlflow has a simple and standardized way to serve models. See https://mlflow.org/docs/latest/models.html for a list of supported models.\n",
    "- you might need more fancy or resilient ways to do so in a very large scale production setup with highly demanding requirements for HA or latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "X = np.array([-2, -1, 0, 1, 2, 1]).reshape(-1, 1)\n",
    "y = np.array([0, 0, 1, 1, 1, 0])\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X, y)\n",
    "score = lr.score(X, y)\n",
    "print(\"Score: %s\" % score)\n",
    "mlflow.log_metric(\"score\", score)\n",
    "mlflow.sklearn.log_model(lr, \"model\")\n",
    "id = mlflow.active_run().info.run_uuid\n",
    "print(f\"Model saved in run {id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To serve execute in a terminal:\n",
    "\n",
    "```bash\n",
    "mlflow models serve -m runs:/<RUN_ID>/model --port 1234\n",
    "\n",
    "# i.e.\n",
    "mlflow models serve -m runs:/83d6af88e83f45ec9c9edff16a0a94b1/model --port 1234\n",
    "```\n",
    "\n",
    "and query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -d '{\"columns\":[\"x\"], \"data\":[[1], [-1]]}' -H 'Content-Type: application/json; format=pandas-split' -X POST localhost:1234/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanup\n",
    "\n",
    "only relevant in case of a local run.\n",
    "If running via docker simply cleanup the no longer used containers.\n",
    "\n",
    "```bash\n",
    "conda env list\n",
    "\n",
    "conda remove --name <<env_name>> --all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
